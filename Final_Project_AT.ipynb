{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English-Sranan Swadesh List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Upload CSV file. The CSV code was created from copying a Swadesh list of English and Sranan (An English-based Creole). The table contains 4 columns. The first column is the English word and the next three columns are Sranan variants. All cells that are empty hold a zero value.  \n",
    "A dictionary was created from the csv. The English words were the key while the Sranan words are the values.\n",
    "\"\"\"\n",
    "    \n",
    "with open('English_Sranan.csv', mode='r') as csv_file:\n",
    "    English_Sranan = csv.reader(csv_file)\n",
    "    with open('test.csv','w') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        dic = {rows[0]:rows[1:4] for rows in English_Sranan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿English: ['SrananV1', 'SrananV2', 'SrananV3']\n",
      "I: ['mi', '0', '0']\n",
      "you (singular): ['yu, i', 'i', '0']\n",
      "he: ['a', 'en', '0']\n",
      "we: ['wi', 'unu', 'un']\n",
      "you (plural): ['unu', 'un', '0']\n",
      "they: ['den', '0', '0']\n",
      "this: ['disi', '0', '0']\n",
      "that: ['dati', '0', '0']\n",
      "here: ['dya', '0', '0']\n",
      "there: ['drape', '0', '0']\n",
      "who: ['suma', '0', '0']\n",
      "what: ['san', 'fa', '0']\n",
      "where: ['pe', '0', '0']\n",
      "when: ['oten', '0', '0']\n",
      "how: ['o', 'fa', '0']\n",
      "not: ['no', '0', '0']\n",
      "all: ['ala', '0', '0']\n",
      "many: ['furu', '0', '0']\n",
      "some: ['son', 'wantu', '0']\n",
      "few: ['wanwan', '0', '0']\n",
      "other: ['tra', '0', '0']\n",
      "one: ['wan', '0', '0']\n",
      "two: ['tu', '0', '0']\n",
      "three: ['dri', '0', '0']\n",
      "four: ['fo', '0', '0']\n",
      "five: ['feifi', '0', '0']\n",
      "big: ['bigi', '0', '0']\n",
      "long: ['langa', '0', '0']\n",
      "wide: ['bradi', '0', '0']\n",
      "thick: ['deki', '0', '0']\n",
      "heavy: ['hebi', '0', '0']\n",
      "small: ['pikin', '0', '0']\n",
      "short: ['syatu', '0', '0']\n",
      "narrow: ['smara', '0', '0']\n",
      "thin: ['fini', 'mangri', '0']\n",
      "woman: ['uma', '0', '0']\n",
      "man (adult male): ['man', '0', '0']\n",
      "man (human being): ['sma', 'libisma', '0']\n",
      "child: ['pikin', 'pikinnengre', '0']\n",
      "wife: ['frow', '0', '0']\n",
      "husband: ['masra', '0', '0']\n",
      "mother: ['mama', '0', '0']\n",
      "father: ['papa', '0', '0']\n",
      "animal: ['meti', '0', '0']\n",
      "fish: ['fisi', '0', '0']\n",
      "bird: ['fowru', '0', '0']\n",
      "dog: ['dagu', '0', '0']\n",
      "louse: ['loso', '0', '0']\n",
      "snake: ['sneki', '0', '0']\n",
      "worm: ['woron', '0', '0']\n",
      "tree: ['bon', '0', '0']\n",
      "forest: ['busi', '0', '0']\n",
      "stick: ['tiki', '0', '0']\n",
      "fruit: ['froktu', '0', '0']\n",
      "seed: ['si', '0', '0']\n",
      "leaf: ['wiwiri', '0', '0']\n",
      "root: ['rutu', '0', '0']\n",
      "bark (of a tree): ['basi', 'buba', '0']\n",
      "flower: ['bromki', '0', '0']\n",
      "grass: ['grasi', '0', '0']\n",
      "rope: ['titei', '0', '0']\n",
      "skin: ['buba', 'skin', '0']\n",
      "meat: ['meti', '0', '0']\n",
      "blood: ['brudu', '0', '0']\n",
      "bone: ['bonyo', '0', '0']\n",
      "fat (noun): ['fatu', '0', '0']\n",
      "egg: ['eksi', '0', '0']\n",
      "horn: ['tutu', '0', '0']\n",
      "tail: ['tere', '0', '0']\n",
      "feather: ['fowruwiwiri', '0', '0']\n",
      "hair: ['wiwiri', '0', '0']\n",
      "head: ['ede', '0', '0']\n",
      "ear: ['yesa', '0', '0']\n",
      "eye: ['ai', '0', '0']\n",
      "nose: ['noso', '0', '0']\n",
      "mouth: ['mofo', '0', '0']\n",
      "tooth: ['tifi', '0', '0']\n",
      "tongue (organ): ['tongo', '0', '0']\n",
      "fingernail: ['nangra', '0', '0']\n",
      "foot: ['futu', '0', '0']\n",
      "leg: ['futu', '0', '0']\n",
      "knee: ['kindi', '0', '0']\n",
      "hand: ['anu', '0', '0']\n",
      "wing: ['frei', '0', '0']\n",
      "belly: ['bere', '0', '0']\n",
      "guts: ['bere', '0', '0']\n",
      "neck: ['neki', '0', '0']\n",
      "back: ['baka', '0', '0']\n",
      "breast: ['bobi', '0', '0']\n",
      "heart: ['ati', '0', '0']\n",
      "liver: ['lefre', '0', '0']\n",
      "drink: ['dringi', '0', '0']\n",
      "eat: ['nyan', '0', '0']\n",
      "bite: ['beti', '0', '0']\n",
      "suck: ['soigi', '0', '0']\n",
      "spit: ['spiti', '0', '0']\n",
      "vomit: ['fomeri', '0', '0']\n",
      "blow: ['wai', 'bro', '0']\n",
      "breathe: ['bro', '0', '0']\n",
      "laught: ['lafu', '0', '0']\n",
      "hear: ['yere', '0', '0']\n",
      "know: ['sabi', '0', '0']\n",
      "think: ['denki', 'prakseri', '0']\n",
      "smell: ['smeri', '0', '0']\n",
      "fear: ['frede', '0', '0']\n",
      "sleep: ['sribi', '0', '0']\n",
      "live: ['libi', '0', '0']\n",
      "die: ['dede', '0', '0']\n",
      "kill: ['kiri', '0', '0']\n",
      "fight: ['feti', 'strei', '0']\n",
      "hunt: ['onti', '0', '0']\n",
      "hit: ['iti', '0', '0']\n",
      "cut: ['koti', '0', '0']\n",
      "split: ['priti', '0', '0']\n",
      "stab: ['dyuku', '0', '0']\n",
      "scratch: ['krabu', 'krasi', '0']\n",
      "dig: ['diki', '0', '0']\n",
      "swim: ['swen', '0', '0']\n",
      "fly: ['frei', '0', '0']\n",
      "walk: ['waka', '0', '0']\n",
      "come: ['kon', '0', '0']\n",
      "lie (as in a bed): ['didon', '0', '0']\n",
      "sit: ['sidon', '0', '0']\n",
      "stand: ['tnapu', 'knapu', 'snapu']\n",
      "turn (intransitive): ['drai', '0', '0']\n",
      "fall: ['fadon', '0', '0']\n",
      "give: ['gi', '0', '0']\n",
      "hold: ['ori', '0', '0']\n",
      "squeeze: ['kwinsi', '0', '0']\n",
      "rub: ['lobi', 'wrifi', '0']\n",
      "wash: ['wasi', 'spuru', '0']\n",
      "wipe: ['wrifi', '0', '0']\n",
      "pull: ['hari', '0', '0']\n",
      "push: ['pusu', '0', '0']\n",
      "throw: ['bonk', 'iti', '0']\n",
      "tie: ['tai', '0', '0']\n",
      "sew: ['nai', '0', '0']\n",
      "count: ['teri', '0', '0']\n",
      "say: ['taki', '0', '0']\n",
      "sing: ['singi', '0', '0']\n",
      "play: ['prei', '0', '0']\n",
      "float: ['dribi', '0', '0']\n",
      "flow: ['lon', '0', '0']\n",
      "freeze: ['0', '0', '0']\n",
      "swell: ['sweri', '0', '0']\n",
      "sun: ['son', '0', '0']\n",
      "moon: ['mun', '0', '0']\n",
      "star: ['stari', '0', '0']\n",
      "water: ['watra', '0', '0']\n",
      "rain: ['alen', '0', '0']\n",
      "river: ['liba', '0', '0']\n",
      "lake: ['0', '0', '0']\n",
      "sea: ['se', '0', '0']\n",
      "salt: ['sowtu', '0', '0']\n",
      "stone: ['ston', '0', '0']\n",
      "sand: ['santi', '0', '0']\n",
      "dust: ['0', '0', '0']\n",
      "earth: ['gron', '0', '0']\n",
      "cloud: ['wolku', '0', '0']\n",
      "fog: ['0', '0', '0']\n",
      "sky: ['loktu', '0', '0']\n",
      "wind: ['winti', '0', '0']\n",
      "snow: ['0', '0', '0']\n",
      "ice: ['0', '0', '0']\n",
      "smoke: ['smoko', '0', '0']\n",
      "fire: ['faya', '0', '0']\n",
      "ash: ['asisi', '0', '0']\n",
      "burn: ['bron', '0', '0']\n",
      "road: ['pasi', '0', '0']\n",
      "mountain: ['bergi', '0', '0']\n",
      "red: ['redi', '0', '0']\n",
      "green: ['grun', '0', '0']\n",
      "yellow: ['geri', '0', '0']\n",
      "white: ['weti', '0', '0']\n",
      "black: ['blaka', '0', '0']\n",
      "night: ['neti', '0', '0']\n",
      "day: ['dei', '0', '0']\n",
      "year: ['yari', '0', '0']\n",
      "warm: ['waran', '0', '0']\n",
      "cold: ['kowru', '0', '0']\n",
      "full: ['furu', '0', '0']\n",
      "new: ['nyun', '0', '0']\n",
      "old: ['owru', '0', '0']\n",
      "good: ['bun', '0', '0']\n",
      "bad: ['ogri', '0', '0']\n",
      "rotten: ['pori', '0', '0']\n",
      "dirty: ['doti', '0', '0']\n",
      "straight: ['leti', '0', '0']\n",
      "round: ['lontu', '0', '0']\n",
      "sharp (as a knife): ['srapu', '0', '0']\n",
      "dull (as a knife): ['dede', '0', '0']\n",
      "smooth: ['grati', '0', '0']\n",
      "wet: ['nati', '0', '0']\n",
      "dry: ['drei', '0', '0']\n",
      "correct: ['yoisti', '0', '0']\n",
      "near: ['na', '0', '0']\n",
      "far: ['fara', '0', '0']\n",
      "right: ['leti-anu', '0', '0']\n",
      "left: ['kruktu-anu', '0', '0']\n",
      "at: ['na', '0', '0']\n",
      "in: ['ini', '0', '0']\n",
      "with: ['nanga', '0', '0']\n",
      "and: ['èn', 'nanga', '0']\n",
      "if: ['efu', '0', '0']\n",
      "because: ['bika', '0', '0']\n",
      "name: ['nen', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"The following code was created to assert that the key and values were correct.\n",
    "\"\"\"\n",
    "for (key, value) in dic.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tnapu', 'knapu', 'snapu']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"The following code is to show the values for a given key. For my project, I am interested in repairs for [s]+C clusters (e.g. \"stand\") in Sranan. I wish to count the frequency of [s] deletion as a repair strategy for sC cluster reduction. This information is based on Ward (2007). \n",
    "    \"\"\"\n",
    "svalue = dic[\"stand\"]\n",
    "svalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"These s cluster items were selected from the sorted dictionary put in a list in order to create a new one that shows all the values for these keys.\n",
    "    \"\"\"\n",
    "slist=['skin',\n",
    " 'sky',\n",
    " 'sleep',\n",
    " 'small',\n",
    " 'smell',\n",
    " 'smoke',\n",
    " 'smooth',\n",
    " 'snake',\n",
    " 'snow',\n",
    " 'spit',\n",
    " 'split',\n",
    " 'squeeze',\n",
    " 'stab',\n",
    " 'stand',\n",
    " 'star',\n",
    " 'stick',\n",
    " 'stone',\n",
    " 'straight',\n",
    " 'swell',\n",
    " 'swim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 sC clusters in the English/Sranan Swadesh list. Out of these words,2 retained their [s]. \n"
     ]
    }
   ],
   "source": [
    "\"\"\"After creating my s list, I created a function that will create a new list that contains the keys (being the s cluster English words) along with their values.\n",
    "    As predicted by Ward, there is not s delection for clusters containing [s] and sonorants. \n",
    "    What is interesting is that there are 4 instances where s is not deleted in a cluster containing an obstruent.\n",
    "    There are also instance where the Sranan translation is does not resemble the English word at all.\n",
    "    In order to clean up the list, I created a function that removes all '0's in the list.\n",
    "      The word snow was deleted as there no Sranan translations or this list. \n",
    " \"\"\"\n",
    "newslist=[]\n",
    "for row in dic.keys():\n",
    "    if row in slist:\n",
    "        newslist.append([row,dic[row]])\n",
    "\n",
    "for line in newslist:\n",
    "    try:\n",
    "        line[1].remove('0')\n",
    "    except:\n",
    "        line[1]\n",
    "\n",
    "\n",
    "newslist\n",
    "\n",
    "Sracol1 = [column for column in newslist if len(column[1])==1]\n",
    "Sracol2 = [column for column in newslist if len(column[1])!=1]\n",
    "engsrlistS = [[pair[0], pair[1][0]] for pair in Sracol1]\n",
    "sclusters = [bb for bb in engsrlistS if bb[1][0] == 's']\n",
    "print(f\"There are {len(newslist)} sC clusters in the English/Sranan Swadesh list. Out of these words,{len(sclusters)+2} retained their [s]. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The following count is based on final world epenthesis for Sranan translations of English words. The first step was to select the words from my dictionary that ended with a consonant. I also deleted the first row as it containt the headings.\n",
    "\"\"\"\n",
    "clist = [word for word in dic.keys() if word[-1] not in ['a','e','i','o','u','y',')', 'I']]\n",
    "del (clist[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'that',\n",
       " 'what',\n",
       " 'when',\n",
       " 'how',\n",
       " 'not',\n",
       " 'all',\n",
       " 'few',\n",
       " 'other',\n",
       " 'four',\n",
       " 'big',\n",
       " 'long',\n",
       " 'thick',\n",
       " 'small',\n",
       " 'short',\n",
       " 'narrow',\n",
       " 'thin',\n",
       " 'woman',\n",
       " 'child',\n",
       " 'husband',\n",
       " 'mother',\n",
       " 'father',\n",
       " 'animal',\n",
       " 'fish',\n",
       " 'bird',\n",
       " 'dog',\n",
       " 'worm',\n",
       " 'forest',\n",
       " 'stick',\n",
       " 'fruit',\n",
       " 'seed',\n",
       " 'leaf',\n",
       " 'root',\n",
       " 'flower',\n",
       " 'grass',\n",
       " 'skin',\n",
       " 'meat',\n",
       " 'blood',\n",
       " 'egg',\n",
       " 'horn',\n",
       " 'tail',\n",
       " 'feather',\n",
       " 'hair',\n",
       " 'head',\n",
       " 'ear',\n",
       " 'mouth',\n",
       " 'tooth',\n",
       " 'fingernail',\n",
       " 'foot',\n",
       " 'leg',\n",
       " 'hand',\n",
       " 'wing',\n",
       " 'guts',\n",
       " 'neck',\n",
       " 'back',\n",
       " 'breast',\n",
       " 'heart',\n",
       " 'liver',\n",
       " 'drink',\n",
       " 'eat',\n",
       " 'suck',\n",
       " 'spit',\n",
       " 'vomit',\n",
       " 'blow',\n",
       " 'laught',\n",
       " 'hear',\n",
       " 'know',\n",
       " 'think',\n",
       " 'smell',\n",
       " 'fear',\n",
       " 'sleep',\n",
       " 'kill',\n",
       " 'fight',\n",
       " 'hunt',\n",
       " 'hit',\n",
       " 'cut',\n",
       " 'split',\n",
       " 'stab',\n",
       " 'scratch',\n",
       " 'dig',\n",
       " 'swim',\n",
       " 'walk',\n",
       " 'sit',\n",
       " 'stand',\n",
       " 'fall',\n",
       " 'hold',\n",
       " 'rub',\n",
       " 'wash',\n",
       " 'pull',\n",
       " 'push',\n",
       " 'throw',\n",
       " 'sew',\n",
       " 'count',\n",
       " 'sing',\n",
       " 'float',\n",
       " 'flow',\n",
       " 'swell',\n",
       " 'sun',\n",
       " 'moon',\n",
       " 'star',\n",
       " 'water',\n",
       " 'rain',\n",
       " 'river',\n",
       " 'salt',\n",
       " 'sand',\n",
       " 'dust',\n",
       " 'earth',\n",
       " 'cloud',\n",
       " 'fog',\n",
       " 'wind',\n",
       " 'snow',\n",
       " 'ash',\n",
       " 'burn',\n",
       " 'road',\n",
       " 'mountain',\n",
       " 'red',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'black',\n",
       " 'night',\n",
       " 'year',\n",
       " 'warm',\n",
       " 'cold',\n",
       " 'full',\n",
       " 'new',\n",
       " 'old',\n",
       " 'good',\n",
       " 'bad',\n",
       " 'rotten',\n",
       " 'straight',\n",
       " 'round',\n",
       " 'smooth',\n",
       " 'wet',\n",
       " 'correct',\n",
       " 'near',\n",
       " 'far',\n",
       " 'right',\n",
       " 'left',\n",
       " 'at',\n",
       " 'in',\n",
       " 'with',\n",
       " 'and',\n",
       " 'if']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 143 words in the English/Sranan Swadesh list that end with a Consonant. Out of these words, 19 have 'a' epenthesis, 6 have 'e' epenthesis, 58 have 'i' epenthesis, 3 have 'o' epenthesis, and 22 have 'u' epenthesis\n"
     ]
    }
   ],
   "source": [
    "\"\"\"After selecting a list of words of words that ended with a consonant, I created a new list that contained only the English words and their Sranan translations.\n",
    "    The next step is to delete all 0 values in the new list.\n",
    "    Next, I created a list that only included English words with 1 Sranan translation. I created functions that included the number of epenthesis per vowel.\n",
    "    Lastly, I printed a short description of the English words and the number Sranan words that have final vowels.\n",
    "\"\"\"\n",
    "newclist=[]\n",
    "for row in dic.keys():\n",
    "    if row in clist:\n",
    "        newclist.append([row,dic[row]])\n",
    "        \n",
    "for line in newclist:\n",
    "    try:\n",
    "        line[1].remove('0')\n",
    "    except:\n",
    "        line[1]\n",
    "\n",
    "Sracol3 = [column for column in newclist if len(column[1])==1]\n",
    "engsrlist2 = [[pair[0], pair[1][0]] for pair in Sracol3]  \n",
    "\n",
    "alist = [bb for bb in engsrlist2 if bb[1][-1] == 'a']\n",
    "elist = [bb for bb in engsrlist2 if bb[1][-1] == 'e']\n",
    "ilist = [bb for bb in engsrlist2 if bb[1][-1] == 'i']\n",
    "olist = [bb for bb in engsrlist2 if bb[1][-1] == 'o']\n",
    "ulist = [bb for bb in engsrlist2 if bb[1][-1] == 'u']        \n",
    "print(f\"There are {len(newclist)} words in the English/Sranan Swadesh list that end with a Consonant. Out of these words, {len(alist)} have 'a' epenthesis, {len(elist)} have 'e' epenthesis, {len(ilist)} have 'i' epenthesis, {len(olist)} have 'o' epenthesis, and {len(ulist)} have 'u' epenthesis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"I wanted to create a separate list to account for the English words that more than one Sranan translation. \"\"\"\n",
    "Sracol4 = [column for column in newclist if len(column[1])!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['what', ['san', 'fa']],\n",
       " ['how', ['o', 'fa']],\n",
       " ['thin', ['fini', 'mangri']],\n",
       " ['child', ['pikin', 'pikinnengre']],\n",
       " ['skin', ['buba', 'skin']],\n",
       " ['blow', ['wai', 'bro']],\n",
       " ['think', ['denki', 'prakseri']],\n",
       " ['fight', ['feti', 'strei']],\n",
       " ['scratch', ['krabu', 'krasi']],\n",
       " ['stand', ['tnapu', 'knapu', 'snapu']],\n",
       " ['rub', ['lobi', 'wrifi']],\n",
       " ['wash', ['wasi', 'spuru']],\n",
       " ['throw', ['bonk', 'iti']],\n",
       " ['snow', []],\n",
       " ['and', ['èn', 'nanga']]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sracol4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I had a difficult time decicing if I wanted to use the following code. It didn't seem necessary to delete the English words that had no translation, but I kept the code.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"I had a difficult time decicing if I wanted to use the following code. It didn't seem necessary to delete the English words that had no translation, but I kept the code.\"\"\"\n",
    "#Sracol4.remove(['dust', []])\n",
    "#Sracol4.remove(['fog', []])\n",
    "#Sracol4.remove(['snow', []])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-03422881b8b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#i2list2 = [bb for bb in Sracol4 if bb[1][1][-1] == 'i' and bb[1][0][-1] != 'i']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#i2list2 = [bb for bb in Sracol4 if bb[1][1][-1] == 'i' and bb[1][0][-1] != 'i']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0malist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSracol4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0melist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSracol4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'e'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0milist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSracol4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-03422881b8b9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#i2list2 = [bb for bb in Sracol4 if bb[1][1][-1] == 'i' and bb[1][0][-1] != 'i']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#i2list2 = [bb for bb in Sracol4 if bb[1][1][-1] == 'i' and bb[1][0][-1] != 'i']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0malist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSracol4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0melist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSracol4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'e'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0milist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSracol4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\"\"\"I ran through multiple attempts on being able to creat functions for counting the secondary Sranana words that had final vowels.  \"\"\"\n",
    "#i2list2 = [bb for bb in Sracol4 if bb[1][0][-1] == 'i'] + [bb for bb in Sracol4 if bb[1][1][-1] == 'i' and bb[1][0][-1] != 'i']\n",
    "#i2list2 = [bb for bb in Sracol4 if bb[1][1][-1] == 'i' and bb[1][0][-1] != 'i']\n",
    "#i2list2 = [bb for bb in Sracol4 if bb[1][1][-1] == 'i' and bb[1][0][-1] != 'i']\n",
    "alist2 = [bb for bb in Sracol4 if bb[1][1][-1] == 'a']\n",
    "elist2 = [bb for bb in Sracol4 if bb[1][1][-1] == 'e']\n",
    "ilist2 = [bb for bb in Sracol4 if bb[1][1][-1] == 'i']\n",
    "olist2 = [bb for bb in Sracol4 if bb[1][1][-1] == 'o']\n",
    "ulist2 = [bb for bb in Sracol4 if bb[1][1][-1] == 'u']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 143 words in the English/Sranan Swadesh list that end with a Consonant. Out of these words, 22 have 'a' epenthesis, 7 have 'e' epenthesis, 64 have 'i' epenthesis, 4 have 'o' epenthesis, and 24 have 'u' epenthesis\n"
     ]
    }
   ],
   "source": [
    "\"\"\"For some reason, I get a Track Error that says that my list index is out of range. However, I am still able to update the count on the number of vowel epentheis\"\"\"\n",
    "print(f\"There are {len(newclist)} words in the English/Sranan Swadesh list that end with a Consonant. Out of these words, {len(alist)+len(alist2)} have 'a' epenthesis, {len(elist)+len(elist2)} have 'e' epenthesis, {len(ilist)+len(ilist2)} have 'i' epenthesis, {len(olist)+len(olist2)} have 'o' epenthesis, and {len(ulist)+len(ulist2)} have 'u' epenthesis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
